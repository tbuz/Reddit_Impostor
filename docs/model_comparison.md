# Model Comparison

## Markov chains 

Markov chains are mathematical systems that hop from one "state" (a situation or set of values) to another. One use of Markov chains is to include real-world phenomena in computer simulations. **Don't really see how they can be relevant for our use case**

## RNN/LSTM

RNNs are neural networks that use internal memory. Because of their internal memory, RNNs can remember important things about the input they received, which allows them to be very precise in predicting whatâ€™s coming next. Can be used in Prediction problems
Language Modelling and Generating Text or Text Summarization, so those models are **relevant to us**

## T5

T5 is a model developed for NLP tasks, it utilizes the transformer architecture and is a pretrained model. **It is very relevant to us**

## BERT 

BERT is also a pretrained model developed for NLP tasks, that utilizes the transformer architecture. **It is very relevant to us**

## GPT
GPT-3, or the third generation Generative Pre-trained Transformer, is a neural network machine learning model trained using internet data to generate any type of text. GPT-3, however, is not open source and it predecessor that is free to use is trained on substantially less data, so it wouldn't achieve such good resulsts as BERT or T5 or XLNET. **It's a very good model, but there seem to be better alternatives**

## XLNET
XLNET is an autoregressive pretrained model for NLP problems that aims to overcome the problems of BERT. **Seems very relevant to us**


